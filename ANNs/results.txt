Pregunta 1.1.a
	 AND
	 LR = 0.01 -> 5 iteraciones
	 LR = 0.05 -> 5 iteraciones
	 LR = 0.1 -> 5 iteraciones
	 LR = 0.2 -> 5 iteraciones
	 LR = 0.3 -> 5 iteraciones
	 LR = 0.4 -> 5 iteraciones
	 LR = 0.5 -> 5 iteraciones
	 LR = 0.99 -> 5 iteraciones

	 OR
	 LR = 0.01 -> 3 iteraciones
	 LR = 0.05 -> 3 iteraciones
	 LR = 0.1 -> 3 iteraciones
	 LR = 0.2 -> 3 iteraciones
	 LR = 0.3 -> 3 iteraciones
	 LR = 0.4 -> 3 iteraciones
	 LR = 0.5 -> 3 iteraciones
	 LR = 0.99 -> 3 iteraciones

	 XOR
	 LR = 0.01 -> No converge Error = 2
	 LR = 0.05 -> No converge Error = 2
	 LR = 0.1 -> No converge Error = 2
	 LR = 0.2 -> No converge Error = 2
	 LR = 0.3 -> No converge Error = 2
	 LR = 0.4 -> No converge Error = 2
	 LR = 0.5 -> No converge Error = 2
	 LR = 0.99 -> No converge Error = 2

Pregunta 1.2.a
	 Diferencia entre Descending Learning Rate y No
	 	    Con DLR para LR "grande" converge más rapido y con menos error 
		    que sin DLR.
		    Pero para DLR con LR "pequeños" converge más rapido pero
		    posiblemente con más error que sin DLR.
Pregunta 1.2.b
	 AND 
	 Con SGD y 1000 iteraciones
	     Time = 
	     	     real    0m0.895s
		     user    0m0.692s
	     	     sys     0m0.084s

		     Resultado equivocado 25% Failure

	  Sin SGD y 1000 iteraciones	     
	      Time =
	      	   real    0m0.892s
		   user    0m0.696s
		   sys     0m0.052s

		   Resultado correcto 0% Failure

	  XOR es lo mismo solo que ambos fallan igual



	 
